---
title: Azure Data Lake の変更データ
description: このトピックでは、Data Lake 内の変更データに関する情報を提供し、それを使用して何ができるかを説明します。
author: MilindaV2
ms.date: 06/10/2021
ms.topic: article
audience: Developer, IT Pro
ms.reviewer: sericks
ms.search.region: Global
ms.author: milindav
ms.search.validFrom: 2021-06-10
ms.openlocfilehash: ab65370bac5fdb55f6c360b2a73554fa01e89e2e
ms.sourcegitcommit: c08a9d19eed1df03f32442ddb65a2adf1473d3b6
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/06/2021
ms.locfileid: "6353718"
---
# <a name="change-data-in-azure-data-lake"></a>Azure Data Lake の変更データ

[!include [banner](../includes/banner.md)]

> [!NOTE]
> **Data Lake へのエクスポート** 機能は、米国、カナダ、英国、ヨーロッパ、南アジア、東アジア、オーストラリア、および日本の地域でパブリック プレビューで表示されます。 Finance and Operations 環境がそれらの地域にある場合は、Microsoft Dynamics Lifecycle Services (LCS) を使用して、環境でこの機能を有効にできます。 この機能を使用するには、[Azure Data Lake へのエクスポートを構成](configure-export-data-lake.md) を参照してください。

Data Lake のデータ変更により、Finance and Operationsアプリのデータ変更に反応するほぼリアルタイムのデータ パイプラインを構築できます。 Data Lake の **変更フィード** フォルダには、Finance and Operations アプリケーションでデータを変更するごとに格納されます。 このフォルダは、**Data Lake へのエクスポート** 機能で作成されます。

## <a name="why-do-you-need-change-data-in-a-data-lake"></a>Data Lake のデータを変更する必要があるのはなぜですか?

Data Lake のデータは、レポートの目的でよく使用されます。 Data Lake のテーブル データを使用してレポートを作成できますが、データの追加コピーを作成してレポートを改善することもできます。 たとえば、パワーユーザーを有効にするように設計されたデータ マートがあるとします。 このデータ マートでは、簡略化された、多くの場合集約されたファクト テーブルと分析コード テーブルを使用している可能性があります。

Data Lake のテーブル データが更新される場合は、対応するファクト テーブルおよび分析コード テーブルを更新した Data Lake に保持する必要があります。 それ以外の場合、レポートには最新のデータが反映されません。

ファクト テーブルと分析コード テーブルを更新する最も簡単な方法は、テーブルを使用して完全なコピーを定期的に作成することです。 ただし、この方法は非効率的です。 テーブルが大きい場合 (たとえば、数千万や数千万の行がある場合) は、完全なコピーを作成してファクト テーブルを更新するプロセスには数時間かかり、大量の計算リソースが消費される場合があります。 したがって、ユーザーが時間内にレポートを作成していない場合があります (つまり、レポートの最新データを表示するために数時間待たなければならない場合があります)。 さらに、データが再処理されるたびに計算リソースが消費されるため、消費したサービスからより大きな請求書を受け取る場合があります。

ファクト テーブルと分析コード テーブルの差分更新は、両方の問題 (時間の消費と計算リソースの消費) に対する答えを提供します。 差分更新では、変更されたレコードのみをソース テーブルから選択し、対応するファクト テーブルおよび分析コード テーブルで更新します。

差分更新は、Azure Data Factory などの多くのデータ変換ツール の標準機能です。 ただし、差分更新機能を使用するには、ソース テーブルで変更されたレコードを識別する必要があります。

**変更フィード** フォルダーには、Data Lake内のテーブル データ変更の履歴が表示されます。 この履歴は、差分更新を使用するデータ パイプラインに使用できます。

## <a name="the-change-feed-folder"></a>変更フィード フォルダー

変更フィード機能は、変更データ キャプチャ (CDC) という名前の SQL Server 機能に依存します。 CDC は、Finance and Operations アプリケーションの背後にあるデータ ストアである SQL Server データベースの変更データをキャプチャするネイティブな方法です。 変更フィード機能を使用すると、Data Lake の CDC 変更ログにアクセスできます。

次の図は、Finance and Operations アプリケーションでの変更フィードの機能を示しています。

![Finance and Operations アプリケーションでの変更フィードがどのように機能するか。](media/Change-feed-overview-picture.png)

1. Finance and Operations アプリケーションでデータが変更されるたびに、基になるデータベース (AXDB) が更新されます。 CDC 機能は、更新がデータベースに反映されることを保証します。 CDC は、論理シーケンス番号 (**LSN** 値)、日付/タイム スタンプ (**日時変更** 値)、および変更されたデータを識別する **ペイロード変更** 値とともに、ログ (変更ログ) に変更をキャプチャします。
2. **Data Lake へのエクスポート** マイクロサービスはデータベース内の変更をキャプチャし、変更ログを顧客の Data Lake に書き込みます。 Data Lake 内の変更フィード フォルダーには、フォルダーに編成された変更ログが含まれています。
3. さらに、**テーブル** フォルダー、変更された各行にはいくつかの新しいフィールドも含まれます。 各行には、対応する変更レコードの **LSN** 値と **日時変更** 値が含まれています。 テーブル フォルダーの **LSN** フィールドと **日時変更** フィールドを使用して、行が変更されたかどうかを識別できますが、最新の変更のみが含まれています。 同じ行が複数回変更された場合は、最新の変更だけが **テーブル** フォルダーに表示されます。

Data Lake 内の特定の変更フィード フォルダーと、対応するテーブル フォルダー内の変更されたフィールドは一貫しています。 したがって、単一のマイクロサービスが、変更フィード フォルダーと Data Lake 内の対応するテーブルの両方を同時に更新します。

## <a name="exploring-the-change-feed-folder-in-your-data-lake"></a>Data Lake 内の変更フィード フォルダを検索

Data Lake にテーブルを追加すると、変更フィードが自動的に有効になります。

Data Lake にテーブルを追加する場合、または非アクティブ化されたテーブルをアクティブ化すると、システムは Data Lake 内のデータの初期コピーを作成します。 この時点で、テーブルの状態は **初期化** と表示されます。 初期コピーが完了すると、状態が **実行中** に変更されます。 テーブルの **実行中** 状態の場合は、Finance and Operations データベース内の変更が Data Lake に反映され、変更フィードが追加されます。

変更フォルダーにアクセスするには、Azure ポータルを開き、Finance and Operations 環境に関連付けられているストレージ アカウントを見つけて選択します。 Data Lake 構造内の **変更フィード** フォルダーが表示されます。 次の図は、例を示します。

![Data Lake フォルダー構造内の変更フィード フォルダー。](media/Change-feed-folders-rootfolder-top-level.png)

**変更フィード** フォルダーを開くと、Data Lake に追加したテーブルに対応するフォルダーが表示されます。 変更フォルダー データを説明する CDM メタデータ ファイルも表示されます。 次の図は、例を示します。

![変更フィード フォルダー内のフォルダーと CDM メタデータ ファイル。](media/Change-feed-folders-table-level-with-metadata.png)

CDM メタデータ ファイルは、フォルダーに含まれる変更フィード データの構造を記述します。 CDM メタデータ ファイルや Data Factory などのデータ変換ツールを使用すると、生のカンマ区切り値 (CSV) ファイルを読み取ることなく、変更フィード データを読み取ることができます。 メタデータを調べるには、メタデータ ファイルを選択し、テキスト エディターで開きます。

![テキスト エディターで開いた CDM メタデータ ファイル。](media/Change-feed-folders-examine-metadata.png)

メタデータ定義から通知されるので、**変更フィード** フォルダーには、追加のフィールドとともに CDC 変更ログの詳細が含まれています。 次の図と表は、変更フォルダーの変更の形式に関する詳細を示しています。

![変更フォルダーの変更の形式。](media/Change-feed-folders-change-data-format2.png)

| フィールド名                    | コンテンツ |
|-------------------------------|----------|
| Start\_LSN                    | <p>このフィールドは、Finance and Operations データベースのソース データを変更したトランザクションの LSN を識別します。</p><p>**注:** **Start\_LSN** 値は、CSV ファイルでは二重引用符で囲まれて **いません**。 これは、SQL Server データベースに示されている 16 進値です。 サンプル値を次に示します: **0X00011E9F00000FB00001**。</p> |
| End\_LSN                      | このフィールドは使用されません。 |
| DML\_Action                   | <p>各変更は個別のレコードとして格納されます。 **DML\_Action** フィールドは、レコードに対する変更を識別します。</p><ul><li>1: DELETE</li><li>2: INSERT</li><li>3: BEFORE\_UPDATE</li><li>4: AFTER\_UPDATE</li></ul><p>**注:** システムは **BEFORE\_UPDATE** レコードを変更フィードに追加されません。</p> |
| Seq\_Val                      | <p>このフィールドは、ソースのデータを変更した LSN 内のシーケンス番号を識別します。 トランザクションは Finance and Operations データベース内の複数のテーブルを更新する可能性があるため、**Seq\_Val** フィールドは CDC がテーブルに割り当てたシーケンス番号を示します。</p><p>変更レコードは、トランザクションのテーブルに対して行われたすべての変更に対して追加されます。 同じレコードが 1 つのトランザクションで複数回更新された場合、個別のシーケンス番号を持つ複数の変更レコードが見つかります。 将来、極端な場合 (たとえば、1 つのトランザクションで同じレコードに数千の更新がある場合)、システムは最新の更新レコードを格納する可能性があります。</p> |
| Update\_Mask                  | 変更されたフィールドを識別するビットマップ。 このビットマップは、変更追跡の更新マスクに似ています。 ただし、ビットマップを調べることで、変更したフィールドを識別できます。 |
| フィールドおよび値の一覧    | 残りの列は、値とともに、テーブルに存在するフィールドのリストを提供します。 トランザクションの一部として変更されたフィールドを識別するには、更新マスクを使用する必要があります。 |
| LastProcessedChange\_DateTime | <p>このフィールドは、Finance and Operations データベースの CDC **日時変更** フィールドの値を提供します。 日付/時刻は、ISO 8601 あたりの協定世界時 (UTC) で表されます。</p><p>サンプル値を次に示します: **"2020-08-24T05:26:03.8622647Z"**。 この値は二重引用符で囲まれていることに注意してください。 さらに、2 番目の値の後の既定の 7 桁の精度と、UTC を表す *Z* が含まれます。</p> |
| DataLakeModified\_DateTime    | <p>このフィールドは、Data Lake への書き込みの日時を提供します。 日付/時刻は、ISO 8601 あたりの UTC で表されます。</p><p>サンプル値を次に示します: **"2020-08-24T05:26:03.8622647Z"**。 この値は二重引用符で囲まれていることに注意してください。 さらに、2 番目の値の後の既定の 7 桁の精度と、UTC を表す *Z* が含まれます。</p> |

## <a name="best-practices-when-change-feeds-are-used"></a>変更フィードを使用する場合のベスト プラクティス

変更フィードは、Finance and Operations アプリの **Data Lake へのエクスポート** 機能によって有効になる強力な機能です。 このセクションでは、変更フィードを使用するときに従う必要のあるいくつかのベスト プラクティスについて説明します。

### <a name="updating-near-real-time-data-marts"></a>ほぼリアルタイムのデータ マートの更新

データ ウェアハウスまたはデータ マートをほぼリアルタイムで更新する必要がある場合 (つまり、Finance and Operations アプリでデータが変更されてから数分以内に更新する必要がある場合)、変更フィードを使用する必要があります。

ただし、理解する必要のある重要な概念がいくつかあります。

- 変更レコードは、サイズが約 4 メガバイト (MB) または 8 MB のファイルにグループ化されます。 Microsoft は、ファイルが Synapse SQL Serverless によってクエリされるときに最適なクエリ応答時間を提供するように、ファイル サイズを最適化しました。 最適化されたファイル サイズ (およびバッチ書き込み) により、Data Lake の更新時に発生する可能性のある Azure の料金も削減されます。 変更レコードは追加されるだけです。 つまり、更新されることはありません。 ただし、**変更フィード** フォルダー内のファイルが更新される場合があります。 たとえば、4 MB のサイズに一致するように小さいレコードがいっぱいになる場合があります。 変更を識別するために、CSV ファイルの日付/タイム スタンプに依存しません。 代わりに、変更レコードの LSN またはタイム スタンプに依存する必要があります。
- 変更フィードは、Data Lake 常に更新されます。 更新は、データを 1 分おきに更新する小規模なバッチで発生する場合があります。 これらの更新は、頻繁に更新されるテーブルの場合、1 分に複数回発生する場合もあります。 **変更フィード** フォルダー (またはファイルのタイム スタンプ) を監視して下流のジョブをトリガーすることはできますが、ファイルに過去に使用した既存の変更レコードが含まれている可能性を考慮する必要があります。
- 下流のジョブは定期的に調整でき、ファイルやフォルダーへの変更を監視する代わりに、マイクロバッチとしてトリガーできます。
- 下流のデータ パイプラインには、「最後に処理された」マーカー (透かしとも呼ばれる) が必要です。 可能な限り、透かしとして LSN を使用する必要があります。 ただし、**日時変更** 値を透かしとして使用することもできます。 LSN に依存することにより、Finance and Operations データベースで確定されたのと同じ順序で変更を確実に消費することができます。
- Finance and Operations でテーブルを再有効化する場合、**変更フィード** フォルダーがクリアされ、システムは次に使用可能な変更から変更フィードを開始します。 この動作によって、変更は **テーブル** フォルダーと一貫しています。 テーブルが再有効化された場合、下流のデータ パイプラインに対する完全な更新をトリガーする必要があります。

[サンプルの Synapse テンプレート](https://github.com/microsoft/Dynamics-365-FastTrack-Implementation-Assets/tree/master/Analytics/SynapseToSQL_ADF) は使用可能です。 これを使用して、SQL ベースのデータ ウェアハウスにデータを段階的に取り込むことができます。

### <a name="simplifying-byod-based-etl-pipelines"></a>BYOD ベースの ETL パイプラインの簡略化

現在[自分のデータベースの持ち込み (BYOD)](../analytics/export-entities-to-your-own-database.md) 機能を使用している場合は、データ管理フレームワーク (DMF) のシステム テーブルまたはバッチ テーブルに基づくエンティティのエクスポートに依存できます。 DMF システム テーブルのエクスポート ジョブ実行データを使用して、エクスポート ジョブの期間を特定している可能性があります。 下流のジョブは、ジョブの実行状態および、DMF テーブルから取得された詳細を介してトリガーされる場合があります。

変更フィードを消費することで、オーケストレーション パイプラインを簡略化できます。

### <a name="using-the-tables-folder-if-your-data-marts-must-be-updated-daily-or-several-times-per-day"></a>データ マートを毎日または 1 日に何度か更新する必要がある場合にテーブル フォルダーを使用する

変更フィードは強力な機能ですが、ほぼリアルタイムのデータ パイプラインを構築および管理するプロセスは複雑です。 最新のデータ変換ツールと既製のテンプレートはこのプロセスを簡素化するのに役立ちますが、パイプラインの構築と実行に投資する必要がある場合があります。

ユーザーがデータ マートを毎日または 1 日に数回更新することを期待している場合、特にデータの量が少ないか中程度の場合は、完全な更新をトリガーすることが経済的な代替になる可能性があります。

### <a name="changing-feeds-to-audit-and-verify-master-data-updates"></a>マスター データの更新を監査および検証するための変更フィード

**変更フィード** フォルダーは、Finance and Operations データベースによって管理される CDC 変更ログの完全な複製です。 Finance and Operations アプリケーションのマスター データに加えた変更は CDC に反映されます。 したがって、拡張機能として、Data Lake の変更フィード フォルダーにも反映されます。

**変更フィード** フォルダー上に構築されたレポートを使用して、システム内のマスター データの変更を監査および検証できます。

### <a name="periodically-purging-the-change-feed-folder"></a>変更フィード フォルダーを定期的に削除する

**変更フィード** フォルダーは、エラーから回復するためにデータを再初期化しない限り、**Data Lake へのエクスポート** プロセスによって削除されません。

テーブルは **実行** 状態の間、変更を追加し続けるため、変更フィード フォルダーは Data Lake 内で拡大し続けます。 (ただし、Data Lake にデータを保持するためのコストは、SQL データベースのコストのほんの一部であることに注意してください。 したがって、データの拡大のコストは大きな問題ではない可能性があります。)

Data Lake に格納されるデータの量を減らしたい場合は、Data Lake から変更ログを定期的に削除できます。 たとえば、90 日または 180 日間変更されていない変更ログ ファイルを削除するジョブを実行できます。

変更ログを定期的に削除しても、**テーブル** フォルダー内のデータには影響しません。 ただし、このトピックで前述されているように、整合性チェックを実行する場合は、それらのチェックを容易にするために、変更ログをより長く保持することをお勧めします。
